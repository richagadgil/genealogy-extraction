{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_string = \"\"\" \n",
    "Electronically signed : Wes Scott, M.D.; Jun 26 2010 11:10AM CST. Obama H. was referred by Dr. Jacob Austin.   \n",
    "Electronically signed by Robert Clowson, M.D.; Janury 15 2015 11:13AM CST \n",
    "Electronically signed by Dr. John Douglas, M.D.; Jun 16 2017 11:13AM CST \n",
    "The patient was referred by \n",
    "Dr. Jayden Green Olivia and Barack Obama.   \n",
    "\"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM: https://stackoverflow.com/questions/51490620/extracting-names-from-a-text-file-using-spacy\n",
    "from spacy.tokens import Span\n",
    "import dateparser\n",
    "import spacy                                                                                                                            \n",
    "nlp = spacy.load('en') \n",
    "\n",
    "def expand_person_entities(doc):\n",
    "    new_ents = []\n",
    "    for ent in doc.ents:\n",
    "        # Only check for title if it's a person and not the first token\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            if ent.start != 0:\n",
    "                # if person preceded by title, include title in entity\n",
    "                prev_token = doc[ent.start - 1]\n",
    "                if prev_token.text in (\"Dr\", \"Dr.\", \"Mr\", \"Mr.\", \"Ms\", \"Ms.\"):\n",
    "                    new_ent = Span(doc, ent.start - 1, ent.end, label=ent.label)\n",
    "                    new_ents.append(new_ent)\n",
    "                else:\n",
    "                    # if entity can be parsed as a date, it's not a person\n",
    "                    if dateparser.parse(ent.text) is None:\n",
    "                        new_ents.append(ent) \n",
    "        else:\n",
    "            new_ents.append(ent)\n",
    "    doc.ents = new_ents\n",
    "    return doc\n",
    "\n",
    "# Add the component after the named entity recognizer\n",
    "# nlp.remove_pipe('expand_person_entities')\n",
    "nlp.add_pipe(expand_person_entities, after='ner')\n",
    "\n",
    "doc = nlp(document_string)\n",
    "person_names = [ent.text for ent in doc.ents if ent.label_=='PERSON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp.add_pipe(expand_person_entities, after='ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_text(text):\n",
    "    doc = nlp(text)\n",
    "    person_names = [ent.text for ent in doc.ents if ent.label_=='PERSON']\n",
    "    new_doc = text\n",
    "    i = 0\n",
    "    for name in person_names:\n",
    "        new_doc = re.sub(name, f'@{i}@', new_doc)\n",
    "        first_name = name.split(' ')[0]\n",
    "        if \".\" not in first_name:\n",
    "            new_doc = re.sub(name, f'@{i}@', new_doc)\n",
    "        i += 1\n",
    "    return new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today @0@ is a great friend. @1@ is a bad friend. '"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_text('Today Michelle is a great friend. Michael is a bad friend. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nElectronically signed : @0@, M.D.; Jun 26 2010 11:10AM CST. @1@ was referred by @2@.   \\nElectronically signed by @3@, M.D.; Janury 15 2015 11:13AM CST \\nElectronically signed by @4@, M.D.; Jun 16 2017 11:13AM CST \\nThe patient was referred by \\n@5@ Olivia and @6@.   \\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = \"Barack Michelle\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wes Scott|Obama H.|Dr. Jacob Austin|Robert Clowson|Dr. John Douglas|Dr. Jayden Green|Barack Obama'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_str = '|'.join(person_names)\n",
    "names_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_joined_names = re.sub(names_str, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_first = [n for n in person_names if ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
